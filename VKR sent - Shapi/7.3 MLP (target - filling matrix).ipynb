{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce296ce2-46cd-434f-ae78-bc8eda7e9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_files.data import data\n",
    "data_ = data.copy()\n",
    "from python_files.matrix.mat_split_data import X_train_mat, X_test_mat, y_train_mat, y_test_mat\n",
    "from python_files.matrix.mat_col_list import mat_x_col_list, mat_col_list_norm, mat_col_list_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309a5278-e48a-411e-9703-e0b5135a7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d3478e-50a5-4e50-9bd2-c6bf97e7808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, QuantileTransformer, MaxAbsScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fe81cb-a93a-4c8e-bc64-cd28f55ddbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae4481-943d-4ef7-a5e6-9208758ec2fa",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f089d65-4adc-4fb8-bd58-97bad94814e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_save_dist = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('normalization', PowerTransformer(), mat_col_list_norm), \n",
    "        ('scaling', StandardScaler(), mat_col_list_std) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb39b61-5537-4a05-af3f-cb888bc4ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_rob = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaling', RobustScaler(), mat_x_col_list)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e421d84b-798a-45fa-b216-a0db527ff8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_maxabs = Pipeline(steps = [('scaling_1', StandardScaler(with_mean=True, with_std=False)),\n",
    "                                     ('scaling_2', MaxAbsScaler())\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c26ca891-9008-4b02-a630-62a066f571e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_std = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaling', StandardScaler(), mat_x_col_list)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14adfbf1-97c2-4457-b0d6-328ede88871c",
   "metadata": {},
   "source": [
    "### Model - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46eaa0a-5903-42ac-b5f9-7742bd0b3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_model():\n",
    "    MLP_model = Sequential()\n",
    "    \n",
    "    MLP_model.add(Dense(56, input_shape = (12,), activation='selu', bias_initializer='glorot_normal', kernel_initializer='glorot_normal',\n",
    "                       activity_regularizer='l1_l2'))\n",
    "    \n",
    "    MLP_model.add(Dropout(0.4))\n",
    "   \n",
    "    MLP_model.add(Dense(44, activation = 'relu', bias_initializer='he_uniform', kernel_initializer='he_uniform',\n",
    "                       activity_regularizer='l1_l2')) \n",
    "    \n",
    "    #MLP_model.add(Dropout(0.0))\n",
    "    \n",
    "    MLP_model.add(Dense(28, activation = 'sigmoid', bias_initializer='glorot_normal', kernel_initializer='he_normal',\n",
    "                       activity_regularizer='l1_l2')) \n",
    "    \n",
    "    MLP_model.add(Dropout(0.4))\n",
    "    \n",
    "    MLP_model.add(Dense(1, activation = 'linear', bias_initializer='he_uniform', kernel_initializer='he_normal',\n",
    "                       activity_regularizer='l1_l2'))\n",
    "    \n",
    "    #adam = Adam(learning_rate = 0.01)\n",
    "    #sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "    MLP_model.compile(loss = 'mean_absolute_error', optimizer = 'RMSprop', metrics=['mean_absolute_error'])\n",
    "    return MLP_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143e1bd5-679e-4f0c-9e33-41af271c6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_mean_absolute_error', factor = 0.2,\n",
    "                              patience = 5, min_lr = 0.0000001, min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5b4a16-0aa0-4ee2-8cf0-e08663fd8ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TransformedTargetRegressor(regressor = KerasRegressor(model = MLP_model(), epochs=300, verbose=True),\n",
    "                                  transformer = QuantileTransformer(n_quantiles = 716, output_distribution = \"normal\", random_state = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70a85556-68ba-4a32-b8b6-08eef13bea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filling_Matrix_Regressor = Pipeline(steps=[('preprocessor', preprocessor_std),\n",
    "                           ('model', model)],\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b27aa-66e5-469e-945f-3624ad7b870e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fb18370-c8a2-41de-aca2-e04023702535",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\WINDOW~1.1\\AppData\\Local\\Temp\\tmp3kvetl9_\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\WINDOW~1.1\\AppData\\Local\\Temp\\tmp3kvetl9_\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "23/23 [==============================] - 1s 3ms/step - loss: 2.9528 - mean_absolute_error: 1.6419\n",
      "Epoch 2/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.2949 - mean_absolute_error: 1.1321\n",
      "Epoch 3/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2.0513 - mean_absolute_error: 1.0005\n",
      "Epoch 4/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.9608 - mean_absolute_error: 1.0155\n",
      "Epoch 5/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.8854 - mean_absolute_error: 1.0252\n",
      "Epoch 6/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.7849 - mean_absolute_error: 0.9970\n",
      "Epoch 7/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.7388 - mean_absolute_error: 1.0049\n",
      "Epoch 8/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.6426 - mean_absolute_error: 0.9628\n",
      "Epoch 9/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.5963 - mean_absolute_error: 0.9649\n",
      "Epoch 10/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.5184 - mean_absolute_error: 0.9310\n",
      "Epoch 11/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.5185 - mean_absolute_error: 0.9642\n",
      "Epoch 12/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.4518 - mean_absolute_error: 0.9323\n",
      "Epoch 13/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.4254 - mean_absolute_error: 0.9385\n",
      "Epoch 14/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.3766 - mean_absolute_error: 0.9195\n",
      "Epoch 15/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.3445 - mean_absolute_error: 0.9158\n",
      "Epoch 16/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.3151 - mean_absolute_error: 0.9151\n",
      "Epoch 17/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.2734 - mean_absolute_error: 0.8989\n",
      "Epoch 18/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.2643 - mean_absolute_error: 0.9146\n",
      "Epoch 19/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.2396 - mean_absolute_error: 0.9121\n",
      "Epoch 20/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1977 - mean_absolute_error: 0.8907\n",
      "Epoch 21/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1659 - mean_absolute_error: 0.8790\n",
      "Epoch 22/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1840 - mean_absolute_error: 0.9144\n",
      "Epoch 23/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1209 - mean_absolute_error: 0.8682\n",
      "Epoch 24/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1327 - mean_absolute_error: 0.8935\n",
      "Epoch 25/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1121 - mean_absolute_error: 0.8852\n",
      "Epoch 26/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1040 - mean_absolute_error: 0.8882\n",
      "Epoch 27/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0715 - mean_absolute_error: 0.8645\n",
      "Epoch 28/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0918 - mean_absolute_error: 0.8919\n",
      "Epoch 29/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0991 - mean_absolute_error: 0.9059\n",
      "Epoch 30/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0671 - mean_absolute_error: 0.8798\n",
      "Epoch 31/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0399 - mean_absolute_error: 0.8571\n",
      "Epoch 32/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0900 - mean_absolute_error: 0.9115\n",
      "Epoch 33/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0621 - mean_absolute_error: 0.8872\n",
      "Epoch 34/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0456 - mean_absolute_error: 0.8746\n",
      "Epoch 35/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0363 - mean_absolute_error: 0.8677\n",
      "Epoch 36/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0347 - mean_absolute_error: 0.8685\n",
      "Epoch 37/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0372 - mean_absolute_error: 0.8743\n",
      "Epoch 38/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.0048 - mean_absolute_error: 0.8444\n",
      "Epoch 39/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0274 - mean_absolute_error: 0.8679\n",
      "Epoch 40/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.0259 - mean_absolute_error: 0.8690\n",
      "Epoch 41/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0131 - mean_absolute_error: 0.8584\n",
      "Epoch 42/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0085 - mean_absolute_error: 0.8554\n",
      "Epoch 43/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9942 - mean_absolute_error: 0.8431\n",
      "Epoch 44/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0151 - mean_absolute_error: 0.8655\n",
      "Epoch 45/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.9928 - mean_absolute_error: 0.8438\n",
      "Epoch 46/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.0219 - mean_absolute_error: 0.8742\n",
      "Epoch 47/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.9829 - mean_absolute_error: 0.8371\n",
      "Epoch 48/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9939 - mean_absolute_error: 0.8494\n",
      "Epoch 49/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9848 - mean_absolute_error: 0.8414\n",
      "Epoch 50/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.9889 - mean_absolute_error: 0.8467\n",
      "Epoch 51/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0173 - mean_absolute_error: 0.8759\n",
      "Epoch 52/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9980 - mean_absolute_error: 0.8580\n",
      "Epoch 53/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.0014 - mean_absolute_error: 0.8615\n",
      "Epoch 54/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.9859 - mean_absolute_error: 0.8461\n",
      "Epoch 55/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9800 - mean_absolute_error: 0.8410\n",
      "Epoch 56/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9768 - mean_absolute_error: 0.8402\n",
      "Epoch 57/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9643 - mean_absolute_error: 0.8288\n",
      "Epoch 58/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9656 - mean_absolute_error: 0.8309\n",
      "Epoch 59/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9752 - mean_absolute_error: 0.8419\n",
      "Epoch 60/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9595 - mean_absolute_error: 0.8264\n",
      "Epoch 61/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9879 - mean_absolute_error: 0.8550\n",
      "Epoch 62/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9605 - mean_absolute_error: 0.8284\n",
      "Epoch 63/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9750 - mean_absolute_error: 0.8433\n",
      "Epoch 64/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9559 - mean_absolute_error: 0.8249\n",
      "Epoch 65/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9773 - mean_absolute_error: 0.8472\n",
      "Epoch 66/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9668 - mean_absolute_error: 0.8373\n",
      "Epoch 67/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9616 - mean_absolute_error: 0.8329\n",
      "Epoch 68/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9813 - mean_absolute_error: 0.8528\n",
      "Epoch 69/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9319 - mean_absolute_error: 0.8037\n",
      "Epoch 70/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9602 - mean_absolute_error: 0.8321\n",
      "Epoch 71/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9509 - mean_absolute_error: 0.8238\n",
      "Epoch 72/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9537 - mean_absolute_error: 0.8274\n",
      "Epoch 73/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9631 - mean_absolute_error: 0.8367\n",
      "Epoch 74/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9527 - mean_absolute_error: 0.8273\n",
      "Epoch 75/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9544 - mean_absolute_error: 0.8296\n",
      "Epoch 76/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9505 - mean_absolute_error: 0.8262\n",
      "Epoch 77/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9605 - mean_absolute_error: 0.8377\n",
      "Epoch 78/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.9532 - mean_absolute_error: 0.8313\n",
      "Epoch 79/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9504 - mean_absolute_error: 0.8279\n",
      "Epoch 80/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.9745 - mean_absolute_error: 0.8528\n",
      "Epoch 81/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9399 - mean_absolute_error: 0.8189\n",
      "Epoch 82/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9371 - mean_absolute_error: 0.8169\n",
      "Epoch 83/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9375 - mean_absolute_error: 0.8176\n",
      "Epoch 84/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9314 - mean_absolute_error: 0.8114\n",
      "Epoch 85/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9504 - mean_absolute_error: 0.8303\n",
      "Epoch 86/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9474 - mean_absolute_error: 0.8277\n",
      "Epoch 87/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9586 - mean_absolute_error: 0.8388\n",
      "Epoch 88/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9518 - mean_absolute_error: 0.8331\n",
      "Epoch 89/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9414 - mean_absolute_error: 0.8235\n",
      "Epoch 90/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9463 - mean_absolute_error: 0.8278\n",
      "Epoch 91/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9231 - mean_absolute_error: 0.8060\n",
      "Epoch 92/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9205 - mean_absolute_error: 0.8035\n",
      "Epoch 93/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9296 - mean_absolute_error: 0.8127\n",
      "Epoch 94/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9413 - mean_absolute_error: 0.8251\n",
      "Epoch 95/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9389 - mean_absolute_error: 0.8228\n",
      "Epoch 96/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9383 - mean_absolute_error: 0.8228\n",
      "Epoch 97/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9252 - mean_absolute_error: 0.8099\n",
      "Epoch 98/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9370 - mean_absolute_error: 0.8221\n",
      "Epoch 99/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9279 - mean_absolute_error: 0.8144\n",
      "Epoch 100/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9301 - mean_absolute_error: 0.8160\n",
      "Epoch 101/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9259 - mean_absolute_error: 0.8121\n",
      "Epoch 102/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9316 - mean_absolute_error: 0.8177\n",
      "Epoch 103/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9371 - mean_absolute_error: 0.8240\n",
      "Epoch 104/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9447 - mean_absolute_error: 0.8331\n",
      "Epoch 105/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9257 - mean_absolute_error: 0.8147\n",
      "Epoch 106/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9065 - mean_absolute_error: 0.7953\n",
      "Epoch 107/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9192 - mean_absolute_error: 0.8073\n",
      "Epoch 108/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9389 - mean_absolute_error: 0.8275\n",
      "Epoch 109/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9245 - mean_absolute_error: 0.8137\n",
      "Epoch 110/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9359 - mean_absolute_error: 0.8263\n",
      "Epoch 111/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9226 - mean_absolute_error: 0.8131\n",
      "Epoch 112/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9264 - mean_absolute_error: 0.8168\n",
      "Epoch 113/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.9222 - mean_absolute_error: 0.8125\n",
      "Epoch 114/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9246 - mean_absolute_error: 0.8159\n",
      "Epoch 115/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9276 - mean_absolute_error: 0.8179\n",
      "Epoch 116/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9272 - mean_absolute_error: 0.8185\n",
      "Epoch 117/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.8996 - mean_absolute_error: 0.7916\n",
      "Epoch 118/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9208 - mean_absolute_error: 0.8130\n",
      "Epoch 119/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9138 - mean_absolute_error: 0.8076\n",
      "Epoch 120/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9185 - mean_absolute_error: 0.8127\n",
      "Epoch 121/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9222 - mean_absolute_error: 0.8166\n",
      "Epoch 122/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9068 - mean_absolute_error: 0.8013\n",
      "Epoch 123/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9187 - mean_absolute_error: 0.8134\n",
      "Epoch 124/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9201 - mean_absolute_error: 0.8155\n",
      "Epoch 125/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9067 - mean_absolute_error: 0.8022\n",
      "Epoch 126/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9006 - mean_absolute_error: 0.7964\n",
      "Epoch 127/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9167 - mean_absolute_error: 0.8134\n",
      "Epoch 128/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9101 - mean_absolute_error: 0.8069\n",
      "Epoch 129/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9208 - mean_absolute_error: 0.8176\n",
      "Epoch 130/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9085 - mean_absolute_error: 0.8041\n",
      "Epoch 131/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9015 - mean_absolute_error: 0.7977\n",
      "Epoch 132/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8928 - mean_absolute_error: 0.7901\n",
      "Epoch 133/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9156 - mean_absolute_error: 0.8130\n",
      "Epoch 134/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9118 - mean_absolute_error: 0.8097\n",
      "Epoch 135/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9146 - mean_absolute_error: 0.8130\n",
      "Epoch 136/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8993 - mean_absolute_error: 0.7973\n",
      "Epoch 137/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9145 - mean_absolute_error: 0.8127\n",
      "Epoch 138/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9143 - mean_absolute_error: 0.8126\n",
      "Epoch 139/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9132 - mean_absolute_error: 0.8119\n",
      "Epoch 140/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9177 - mean_absolute_error: 0.8161\n",
      "Epoch 141/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9148 - mean_absolute_error: 0.8135\n",
      "Epoch 142/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9060 - mean_absolute_error: 0.8058\n",
      "Epoch 143/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9059 - mean_absolute_error: 0.8068\n",
      "Epoch 144/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8927 - mean_absolute_error: 0.7938\n",
      "Epoch 145/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8997 - mean_absolute_error: 0.8008\n",
      "Epoch 146/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.8953 - mean_absolute_error: 0.7963\n",
      "Epoch 147/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9088 - mean_absolute_error: 0.8105\n",
      "Epoch 148/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9001 - mean_absolute_error: 0.8020\n",
      "Epoch 149/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9096 - mean_absolute_error: 0.8119\n",
      "Epoch 150/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8880 - mean_absolute_error: 0.7910\n",
      "Epoch 151/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9020 - mean_absolute_error: 0.8041\n",
      "Epoch 152/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9041 - mean_absolute_error: 0.8067\n",
      "Epoch 153/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8844 - mean_absolute_error: 0.7880\n",
      "Epoch 154/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8851 - mean_absolute_error: 0.7890\n",
      "Epoch 155/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9012 - mean_absolute_error: 0.8054\n",
      "Epoch 156/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9023 - mean_absolute_error: 0.8073\n",
      "Epoch 157/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8844 - mean_absolute_error: 0.7891\n",
      "Epoch 158/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8971 - mean_absolute_error: 0.8024\n",
      "Epoch 159/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9011 - mean_absolute_error: 0.8054\n",
      "Epoch 160/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9060 - mean_absolute_error: 0.8099\n",
      "Epoch 161/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8897 - mean_absolute_error: 0.7947\n",
      "Epoch 162/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8750 - mean_absolute_error: 0.7787\n",
      "Epoch 163/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8715 - mean_absolute_error: 0.7755\n",
      "Epoch 164/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8879 - mean_absolute_error: 0.7929\n",
      "Epoch 165/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9057 - mean_absolute_error: 0.8110\n",
      "Epoch 166/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8964 - mean_absolute_error: 0.8015\n",
      "Epoch 167/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8910 - mean_absolute_error: 0.7965\n",
      "Epoch 168/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9122 - mean_absolute_error: 0.8183\n",
      "Epoch 169/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8952 - mean_absolute_error: 0.8010\n",
      "Epoch 170/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8869 - mean_absolute_error: 0.7930\n",
      "Epoch 171/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9017 - mean_absolute_error: 0.8079\n",
      "Epoch 172/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8793 - mean_absolute_error: 0.7857\n",
      "Epoch 173/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8820 - mean_absolute_error: 0.7893\n",
      "Epoch 174/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8809 - mean_absolute_error: 0.7877\n",
      "Epoch 175/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8934 - mean_absolute_error: 0.8007\n",
      "Epoch 176/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8923 - mean_absolute_error: 0.7985\n",
      "Epoch 177/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8864 - mean_absolute_error: 0.7940\n",
      "Epoch 178/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8868 - mean_absolute_error: 0.7947\n",
      "Epoch 179/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8922 - mean_absolute_error: 0.8008\n",
      "Epoch 180/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8887 - mean_absolute_error: 0.7980\n",
      "Epoch 181/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8942 - mean_absolute_error: 0.8041\n",
      "Epoch 182/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8936 - mean_absolute_error: 0.8039\n",
      "Epoch 183/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8777 - mean_absolute_error: 0.7881\n",
      "Epoch 184/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8841 - mean_absolute_error: 0.7943\n",
      "Epoch 185/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8878 - mean_absolute_error: 0.7978\n",
      "Epoch 186/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8864 - mean_absolute_error: 0.7967\n",
      "Epoch 187/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8816 - mean_absolute_error: 0.7927\n",
      "Epoch 188/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8847 - mean_absolute_error: 0.7956\n",
      "Epoch 189/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8855 - mean_absolute_error: 0.7961\n",
      "Epoch 190/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8866 - mean_absolute_error: 0.7975\n",
      "Epoch 191/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8759 - mean_absolute_error: 0.7869\n",
      "Epoch 192/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8838 - mean_absolute_error: 0.7946\n",
      "Epoch 193/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8845 - mean_absolute_error: 0.7961\n",
      "Epoch 194/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8720 - mean_absolute_error: 0.7837\n",
      "Epoch 195/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8754 - mean_absolute_error: 0.7868\n",
      "Epoch 196/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8825 - mean_absolute_error: 0.7935\n",
      "Epoch 197/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8798 - mean_absolute_error: 0.7911\n",
      "Epoch 198/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8957 - mean_absolute_error: 0.8070\n",
      "Epoch 199/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8781 - mean_absolute_error: 0.7898\n",
      "Epoch 200/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8758 - mean_absolute_error: 0.7873\n",
      "Epoch 201/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9045 - mean_absolute_error: 0.8154\n",
      "Epoch 202/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8572 - mean_absolute_error: 0.7691\n",
      "Epoch 203/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8904 - mean_absolute_error: 0.8023\n",
      "Epoch 204/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8792 - mean_absolute_error: 0.7912\n",
      "Epoch 205/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8711 - mean_absolute_error: 0.7831\n",
      "Epoch 206/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8746 - mean_absolute_error: 0.7858\n",
      "Epoch 207/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8895 - mean_absolute_error: 0.8007\n",
      "Epoch 208/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8809 - mean_absolute_error: 0.7922\n",
      "Epoch 209/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8720 - mean_absolute_error: 0.7833\n",
      "Epoch 210/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8861 - mean_absolute_error: 0.7979\n",
      "Epoch 211/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8918 - mean_absolute_error: 0.8044\n",
      "Epoch 212/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8885 - mean_absolute_error: 0.8008\n",
      "Epoch 213/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8813 - mean_absolute_error: 0.7945\n",
      "Epoch 214/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8864 - mean_absolute_error: 0.7997\n",
      "Epoch 215/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8665 - mean_absolute_error: 0.7804\n",
      "Epoch 216/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8758 - mean_absolute_error: 0.7900\n",
      "Epoch 217/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8808 - mean_absolute_error: 0.7948\n",
      "Epoch 218/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8686 - mean_absolute_error: 0.7827\n",
      "Epoch 219/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8741 - mean_absolute_error: 0.7880\n",
      "Epoch 220/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8882 - mean_absolute_error: 0.8017\n",
      "Epoch 221/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8766 - mean_absolute_error: 0.7906\n",
      "Epoch 222/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8613 - mean_absolute_error: 0.7749\n",
      "Epoch 223/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8635 - mean_absolute_error: 0.7781\n",
      "Epoch 224/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8817 - mean_absolute_error: 0.7962\n",
      "Epoch 225/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8746 - mean_absolute_error: 0.7893\n",
      "Epoch 226/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8826 - mean_absolute_error: 0.7975\n",
      "Epoch 227/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8609 - mean_absolute_error: 0.7760\n",
      "Epoch 228/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8744 - mean_absolute_error: 0.7895\n",
      "Epoch 229/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8708 - mean_absolute_error: 0.7850\n",
      "Epoch 230/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8674 - mean_absolute_error: 0.7820\n",
      "Epoch 231/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8733 - mean_absolute_error: 0.7885\n",
      "Epoch 232/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8727 - mean_absolute_error: 0.7883\n",
      "Epoch 233/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8826 - mean_absolute_error: 0.7966\n",
      "Epoch 234/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8731 - mean_absolute_error: 0.7874\n",
      "Epoch 235/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8721 - mean_absolute_error: 0.7869\n",
      "Epoch 236/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8774 - mean_absolute_error: 0.7924\n",
      "Epoch 237/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8815 - mean_absolute_error: 0.7968\n",
      "Epoch 238/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8808 - mean_absolute_error: 0.7971\n",
      "Epoch 239/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8740 - mean_absolute_error: 0.7901\n",
      "Epoch 240/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8602 - mean_absolute_error: 0.7772\n",
      "Epoch 241/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8665 - mean_absolute_error: 0.7835\n",
      "Epoch 242/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8654 - mean_absolute_error: 0.7828\n",
      "Epoch 243/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8683 - mean_absolute_error: 0.7848\n",
      "Epoch 244/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8635 - mean_absolute_error: 0.7804\n",
      "Epoch 245/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8804 - mean_absolute_error: 0.7965\n",
      "Epoch 246/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8720 - mean_absolute_error: 0.7892\n",
      "Epoch 247/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8765 - mean_absolute_error: 0.7936\n",
      "Epoch 248/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8711 - mean_absolute_error: 0.7872\n",
      "Epoch 249/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8664 - mean_absolute_error: 0.7837\n",
      "Epoch 250/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8803 - mean_absolute_error: 0.7975\n",
      "Epoch 251/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8705 - mean_absolute_error: 0.7878\n",
      "Epoch 252/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8626 - mean_absolute_error: 0.7801\n",
      "Epoch 253/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.8650 - mean_absolute_error: 0.7823\n",
      "Epoch 254/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8625 - mean_absolute_error: 0.7807\n",
      "Epoch 255/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8572 - mean_absolute_error: 0.7755\n",
      "Epoch 256/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8650 - mean_absolute_error: 0.7833\n",
      "Epoch 257/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8633 - mean_absolute_error: 0.7822\n",
      "Epoch 258/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8530 - mean_absolute_error: 0.7716\n",
      "Epoch 259/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8646 - mean_absolute_error: 0.7839\n",
      "Epoch 260/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8606 - mean_absolute_error: 0.7801\n",
      "Epoch 261/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8642 - mean_absolute_error: 0.7835\n",
      "Epoch 262/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8632 - mean_absolute_error: 0.7817\n",
      "Epoch 263/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8712 - mean_absolute_error: 0.7900\n",
      "Epoch 264/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8654 - mean_absolute_error: 0.7838\n",
      "Epoch 265/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8660 - mean_absolute_error: 0.7850\n",
      "Epoch 266/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8606 - mean_absolute_error: 0.7804\n",
      "Epoch 267/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8702 - mean_absolute_error: 0.7896\n",
      "Epoch 268/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8564 - mean_absolute_error: 0.7756\n",
      "Epoch 269/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8563 - mean_absolute_error: 0.7760\n",
      "Epoch 270/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8547 - mean_absolute_error: 0.7741\n",
      "Epoch 271/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8588 - mean_absolute_error: 0.7780\n",
      "Epoch 272/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8663 - mean_absolute_error: 0.7855\n",
      "Epoch 273/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8617 - mean_absolute_error: 0.7811\n",
      "Epoch 274/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8611 - mean_absolute_error: 0.7811\n",
      "Epoch 275/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8676 - mean_absolute_error: 0.7871\n",
      "Epoch 276/300\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.8698 - mean_absolute_error: 0.7909\n",
      "Epoch 277/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8548 - mean_absolute_error: 0.7758\n",
      "Epoch 278/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8618 - mean_absolute_error: 0.7833\n",
      "Epoch 279/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8632 - mean_absolute_error: 0.7845\n",
      "Epoch 280/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8572 - mean_absolute_error: 0.7783\n",
      "Epoch 281/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8610 - mean_absolute_error: 0.7820\n",
      "Epoch 282/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8634 - mean_absolute_error: 0.7850\n",
      "Epoch 283/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8564 - mean_absolute_error: 0.7776\n",
      "Epoch 284/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8638 - mean_absolute_error: 0.7847\n",
      "Epoch 285/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8540 - mean_absolute_error: 0.7752\n",
      "Epoch 286/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8693 - mean_absolute_error: 0.7898\n",
      "Epoch 287/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8587 - mean_absolute_error: 0.7804\n",
      "Epoch 288/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8674 - mean_absolute_error: 0.7884\n",
      "Epoch 289/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8580 - mean_absolute_error: 0.7793\n",
      "Epoch 290/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8610 - mean_absolute_error: 0.7824\n",
      "Epoch 291/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8592 - mean_absolute_error: 0.7808\n",
      "Epoch 292/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8629 - mean_absolute_error: 0.7844\n",
      "Epoch 293/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8615 - mean_absolute_error: 0.7840\n",
      "Epoch 294/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8574 - mean_absolute_error: 0.7796\n",
      "Epoch 295/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8638 - mean_absolute_error: 0.7857\n",
      "Epoch 296/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8537 - mean_absolute_error: 0.7758\n",
      "Epoch 297/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8633 - mean_absolute_error: 0.7861\n",
      "Epoch 298/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8509 - mean_absolute_error: 0.7741\n",
      "Epoch 299/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8596 - mean_absolute_error: 0.7826\n",
      "Epoch 300/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8682 - mean_absolute_error: 0.7916\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=  31.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;scaling&#x27;, StandardScaler(),\n",
       "                                                  Index([&#x27;, /3&#x27;, &#x27; , &#x27;,\n",
       "       &#x27; , .%&#x27;, &#x27;  ,%_2&#x27;,\n",
       "       &#x27; , _2&#x27;, &#x27; , /2&#x27;,\n",
       "       &#x27;   , &#x27;, &#x27;  , &#x27;,\n",
       "       &#x27; , /2&#x27;, &#x27; , &#x27;, &#x27; &#x27;,\n",
       "       &#x27; &#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 TransformedTargetRegressor(regressor=KerasRegressor(epochs=300, model=&lt;keras.engine.sequential.Sequential object at 0x0000003DBC820370&gt;, verbose=True),\n",
       "                                            transformer=QuantileTransformer(n_quantiles=716,\n",
       "                                                                            output_distribution=&#x27;normal&#x27;,\n",
       "                                                                            random_state=7)))],\n",
       "         verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;scaling&#x27;, StandardScaler(),\n",
       "                                                  Index([&#x27;, /3&#x27;, &#x27; , &#x27;,\n",
       "       &#x27; , .%&#x27;, &#x27;  ,%_2&#x27;,\n",
       "       &#x27; , _2&#x27;, &#x27; , /2&#x27;,\n",
       "       &#x27;   , &#x27;, &#x27;  , &#x27;,\n",
       "       &#x27; , /2&#x27;, &#x27; , &#x27;, &#x27; &#x27;,\n",
       "       &#x27; &#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 TransformedTargetRegressor(regressor=KerasRegressor(epochs=300, model=&lt;keras.engine.sequential.Sequential object at 0x0000003DBC820370&gt;, verbose=True),\n",
       "                                            transformer=QuantileTransformer(n_quantiles=716,\n",
       "                                                                            output_distribution=&#x27;normal&#x27;,\n",
       "                                                                            random_state=7)))],\n",
       "         verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;scaling&#x27;, StandardScaler(),\n",
       "                                 Index([&#x27;, /3&#x27;, &#x27; , &#x27;,\n",
       "       &#x27; , .%&#x27;, &#x27;  ,%_2&#x27;,\n",
       "       &#x27; , _2&#x27;, &#x27; , /2&#x27;,\n",
       "       &#x27;   , &#x27;, &#x27;  , &#x27;,\n",
       "       &#x27; , /2&#x27;, &#x27; , &#x27;, &#x27; &#x27;,\n",
       "       &#x27; &#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaling</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;, /3&#x27;, &#x27; , &#x27;,\n",
       "       &#x27; , .%&#x27;, &#x27;  ,%_2&#x27;,\n",
       "       &#x27; , _2&#x27;, &#x27; , /2&#x27;,\n",
       "       &#x27;   , &#x27;, &#x27;  , &#x27;,\n",
       "       &#x27; , /2&#x27;, &#x27; , &#x27;, &#x27; &#x27;,\n",
       "       &#x27; &#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: TransformedTargetRegressor</label><div class=\"sk-toggleable__content\"><pre>TransformedTargetRegressor(regressor=KerasRegressor(epochs=300, model=&lt;keras.engine.sequential.Sequential object at 0x0000003DBC820370&gt;, verbose=True),\n",
       "                           transformer=QuantileTransformer(n_quantiles=716,\n",
       "                                                           output_distribution=&#x27;normal&#x27;,\n",
       "                                                           random_state=7))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">regressor: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;keras.engine.sequential.Sequential object at 0x0000003DBC820370&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=True\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=300\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;keras.engine.sequential.Sequential object at 0x0000003DBC820370&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=True\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=300\n",
       ")</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer(n_quantiles=716, output_distribution=&#x27;normal&#x27;,\n",
       "                    random_state=7)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer(n_quantiles=716, output_distribution=&#x27;normal&#x27;,\n",
       "                    random_state=7)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('scaling', StandardScaler(),\n",
       "                                                  Index([', /3', ' , ',\n",
       "       ' , .%', '  ,%_2',\n",
       "       ' , _2', ' , /2',\n",
       "       '   , ', '  , ',\n",
       "       ' , /2', ' , ', ' ',\n",
       "       ' '],\n",
       "      dtype='object'))])),\n",
       "                ('model',\n",
       "                 TransformedTargetRegressor(regressor=KerasRegressor(epochs=300, model=<keras.engine.sequential.Sequential object at 0x0000003DBC820370>, verbose=True),\n",
       "                                            transformer=QuantileTransformer(n_quantiles=716,\n",
       "                                                                            output_distribution='normal',\n",
       "                                                                            random_state=7)))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Filling_Matrix_Regressor.fit(X_train_mat, y_train_mat, model__callbacks = [reduce_lr])     #, model__epochs = 200, model__verbose = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b9dcb-4f0e-460f-98c5-02aca6cb67bf",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0013d8b2-1093-4e54-9fca-f338f4c83b27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = Filling_Matrix_Regressor.predict(X_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fb318f1-d8d3-4300-8cb0-51992d27e558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_train = Filling_Matrix_Regressor.predict(X_train_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffdad57-a879-4052-b2ca-797e1848ff57",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0697ff8-e8d3-47d4-ac06-aaf110fde27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09264480870896352, -0.0650039084696925)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train_mat, preds_train), r2_score(y_test_mat, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57431ab5-8ff7-4ad3-9f76-2850f0215197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7049152082005635, 0.6989356896370008)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train_mat, preds_train), mean_absolute_error(y_test_mat, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89ea40d3-f098-4632-9e36-80f637ae92fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8870789911821112, 0.8958564661261903)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_train_mat, preds_train)), np.sqrt(mean_squared_error(y_test_mat, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4531fb0-c4fe-465c-aab2-c3c02a82d689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.435027792454662"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test_mat, preds) * 100 / (y_test_mat.max() - y_test_mat.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05d32b25-886d-4522-8496-63b2244410a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    307.000000\n",
       "mean       2.937117\n",
       "std        0.869503\n",
       "min        0.389403\n",
       "25%        2.370830\n",
       "50%        2.920376\n",
       "75%        3.495788\n",
       "max        5.591742\n",
       "Name:  -, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_mat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e97127d-fc19-4417-be8f-34f02943c41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
